# üõ°Ô∏è Syst√®me Avanc√© de D√©tection de Fraude

## Table des Mati√®res
1. [Vue d'ensemble du Projet](#vue-densemble-du-projet)
2. [Contexte Business](#contexte-business)
3. [Architecture Technique](#architecture-technique)
4. [Dataset et Donn√©es](#dataset-et-donn√©es)
5. [Mod√®le de Machine Learning](#mod√®le-de-machine-learning)
6. [API Backend (FastAPI)](#api-backend-fastapi)
7. [Dashboard Interactif (Streamlit)](#dashboard-interactif-streamlit)
8. [Guide d'Installation](#guide-dinstallation)
9. [Guide d'Utilisation](#guide-dutilisation)
10. [R√©sultats et Performance](#r√©sultats-et-performance)
11. [Am√©liorations Futures](#am√©liorations-futures)

---

## Vue d'ensemble du Projet

Ce projet est un **syst√®me de d√©tection de fraude en temps r√©el** qui utilise des techniques avanc√©es de machine learning pour identifier les transactions frauduleuses dans un environnement bancaire/financier. Le syst√®me combine:

- **Machine Learning avanc√©** avec XGBoost
- **API REST** pour l'inf√©rence en temps r√©el
- **Dashboard interactif** pour la visualisation et les tests

### Objectifs Principaux
1. ‚úÖ D√©tecter les fraudes avec une haute pr√©cision (Recall ‚â• 95%)
2. ‚úÖ Fournir des pr√©dictions en temps r√©el via API
3. ‚úÖ Offrir une interface utilisateur pour analyser les transactions
4. ‚úÖ Minimiser les faux positifs tout en maximisant la d√©tection des fraudes

---

## Contexte Business

### Probl√©matique
Les fraudes bancaires repr√©sentent un enjeu majeur pour les institutions financi√®res:
- **Pertes financi√®res** directes pour les clients et les banques
- **Atteinte √† la r√©putation** en cas de fraudes non d√©tect√©es
- **D√©s√©quilibre des donn√©es**: seulement ~1.5% des transactions sont frauduleuses

### Solution Propos√©e
Un syst√®me automatis√© qui:
- Analyse chaque transaction en temps r√©el
- Calcule un score de probabilit√© de fraude
- Bloque ou signale les transactions suspectes
- Permet aux analystes de r√©viser les d√©cisions

### Valeur Ajout√©e
- **R√©duction des pertes** gr√¢ce √† la d√©tection pr√©coce
- **Am√©lioration de l'exp√©rience client** (moins de faux blocages)
- **Scalabilit√©** pour traiter des millions de transactions

---

## Architecture Technique

Le syst√®me est compos√© de **3 couches principales**:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    DASHBOARD (Streamlit)                 ‚îÇ
‚îÇ  - Visualisation des donn√©es                            ‚îÇ
‚îÇ  - Test de transactions                                 ‚îÇ
‚îÇ  - Insights et m√©triques                                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ HTTP Requests
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 API BACKEND (FastAPI)                    ‚îÇ
‚îÇ  - Endpoint /predict                                     ‚îÇ
‚îÇ  - Endpoint /health                                      ‚îÇ
‚îÇ  - Chargement du mod√®le                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                     ‚îÇ Inference
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              MOD√àLE ML (XGBoost)                         ‚îÇ
‚îÇ  - Pipeline de preprocessing                            ‚îÇ
‚îÇ  - Classificateur XGBoost                               ‚îÇ
‚îÇ  - Fichiers: fraud_model_xgboost.pkl                   ‚îÇ
‚îÇ              model_metadata.pkl                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Stack Technique
| Composant | Technologie | R√¥le |
|-----------|-------------|------|
| **ML Framework** | XGBoost 3.1+ | Mod√®le de classification |
| **Preprocessing** | Scikit-learn | Standardisation, encodage |
| **API Backend** | FastAPI | Endpoint REST |
| **Dashboard** | Streamlit | Interface utilisateur |
| **Data Processing** | Pandas, NumPy | Manipulation des donn√©es |
| **Visualisation** | Plotly, Matplotlib, Seaborn | Graphiques |

---

## Dataset et Donn√©es

### Origine des Donn√©es
Le dataset `fraud_dataset_realistic_200k.csv` contient **200 000 transactions synth√©tiques** g√©n√©r√©es avec des patterns de fraude r√©alistes.

### Structure des Donn√©es (27 colonnes)

#### **Identifiants**
- `transaction_id`: UUID unique de la transaction
- `customer_id`: Identifiant client
- `merchant_id`: Identifiant marchand

#### **Informations Temporelles**
- `transaction_time`: Timestamp ISO (YYYY-MM-DDTHH:MM:SS)
- `transaction_hour`: Heure de la transaction (0-23)
- `day_of_week`: Jour de la semaine (0=Lundi, 6=Dimanche)

#### **Informations Client**
- `age`: √Çge du client (18-90 ans)
- `gender`: Genre (M/F/U)
- `home_country`: Pays de r√©sidence
- `balance`: Solde du compte

#### **Informations Transaction**
- `transaction_country`: Pays de la transaction
- `merchant_category`: Cat√©gorie (grocery, travel, electronics, etc.)
- `transaction_type`: Type (online/in_store)
- `card_type`: Type de carte (Visa, Mastercard, etc.)
- `device`: Appareil utilis√© (mobile, desktop, pos_terminal, tablet)
- `amount`: Montant de la transaction

#### **Features Calcul√©es**
- `avg_30d_amount`: Montant moyen des 30 derniers jours
- `previous_transactions_24h`: Nombre de transactions dans les 24h
- `last_hour_transactions`: Nombre de transactions dans la derni√®re heure
- `ip_risk_score`: Score de risque de l'IP (0-100)
- `merchant_base_risk`: Risque de base du marchand (0-1)

#### **Indicateurs de Risque**
- `is_foreign`: Transaction √† l'√©tranger (0/1)
- `device_mismatch`: Appareil inhabituel (0/1)
- `location_change`: Changement de localisation (0/1)
- `amount_anomaly`: Anomalie de montant (-1 √† 1)
- `hour_anomaly`: Heure inhabituelle (0/1)

#### **Label**
- `label_is_fraud`: Cible (0=l√©gitime, 1=fraude)

### Distribution des Donn√©es
- **Total transactions**: 200 000
- **Transactions frauduleuses**: ~3 000 (1.5%)
- **Transactions l√©gitimes**: ~197 000 (98.5%)
- **D√©s√©quilibre**: Ratio 1:65 (typique des fraudes r√©elles)

### Patterns de Fraude Inclus
1. **Ring Frauds**: Groupes de clients et marchands coordonn√©s
2. **Account Takeover**: Prise de contr√¥le de compte avec transactions suspectes
3. **Card Testing**: Multiples petites transactions suivies d'une grosse
4. **Transactions √©trang√®res**: Achats en ligne depuis l'√©tranger

---

## Mod√®le de Machine Learning

### Choix du Mod√®le: XGBoost

**XGBoost** (Extreme Gradient Boosting) a √©t√© s√©lectionn√© pour:
- ‚úÖ **Performance sup√©rieure** sur les donn√©es tabulaires
- ‚úÖ **Gestion native du d√©s√©quilibre** via `scale_pos_weight`
- ‚úÖ **Rapidit√© d'inf√©rence** (crucial pour le temps r√©el)
- ‚úÖ **R√©sistance au surapprentissage** gr√¢ce √† la r√©gularisation

### Pipeline de Preprocessing

```python
ColumnTransformer([
    ('num', StandardScaler(), numerical_cols),
    ('cat', OneHotEncoder(), categorical_cols)
])
```

#### **Transformations Num√©riques**
- Standardisation (z-score normalization)
- Moyenne = 0, √âcart-type = 1
- Colonnes: `age`, `amount`, `balance`, `ip_risk_score`, etc.

#### **Transformations Cat√©gorielles**
- One-Hot Encoding
- Gestion des cat√©gories inconnues (`handle_unknown='ignore'`)
- Colonnes: `gender`, `merchant_category`, `transaction_type`, etc.

### Hyperparam√®tres du Mod√®le

```python
XGBClassifier(
    n_estimators=200,           # Nombre d'arbres
    learning_rate=0.05,         # Taux d'apprentissage
    max_depth=6,                # Profondeur max des arbres
    subsample=0.8,              # √âchantillonnage des lignes
    colsample_bytree=0.8,       # √âchantillonnage des colonnes
    scale_pos_weight=10,        # Poids pour la classe minoritaire
    eval_metric='aucpr',        # M√©trique de validation
    random_state=42,
    n_jobs=-1                   # Parall√©lisation
)
```

### Strat√©gie de Validation
- **Split**: 80% train / 20% test
- **Stratification**: Pr√©serve le ratio fraude/l√©gitime
- **Seed**: 42 (reproductibilit√©)

### Optimisation du Seuil
Le seuil de d√©cision est optimis√© pour atteindre **95% de Recall**:
1. Calcul de la courbe Precision-Recall
2. Recherche du seuil donnant Recall ‚â• 0.95
3. Stockage dans `model_metadata.pkl`

**Seuil optimal**: ~0.0174 (au lieu du 0.5 par d√©faut)

---

## API Backend (FastAPI)

### Fichier: `app_fastapi.py`

FastAPI a √©t√© choisi pour:
- ‚ö° **Performance**: Asyncio natif, tr√®s rapide
- üìù **Documentation auto**: Swagger UI int√©gr√©
- ‚úÖ **Validation**: Pydantic pour les schemas
- üîß **Simple √† maintenir**: Code minimaliste

### Endpoints

#### **GET /health**
V√©rification de l'√©tat du service et du mod√®le.

**R√©ponse**:
```json
{
  "status": "active",
  "model_loaded": true
}
```

#### **POST /predict**
Pr√©diction de fraude pour une transaction.

**Requ√™te** (exemple):
```json
{
  "transaction_hour": 14,
  "day_of_week": 2,
  "age": 35,
  "gender": "M",
  "home_country": "US",
  "transaction_country": "US",
  "merchant_category": "electronics",
  "merchant_base_risk": 0.15,
  "transaction_type": "online",
  "card_type": "Visa",
  "device": "mobile",
  "amount": 250.00,
  "avg_30d_amount": 80.00,
  "previous_transactions_24h": 2,
  "last_hour_transactions": 0,
  "balance": 1500.00,
  "ip_risk_score": 25.5,
  "is_foreign": 0,
  "device_mismatch": 0,
  "location_change": 0,
  "amount_anomaly": 0.35,
  "hour_anomaly": 0
}
```

**R√©ponse**:
```json
{
  "fraud_probability": 0.0823,
  "is_fraud": false,
  "threshold_used": 0.0174,
  "risk_level": "Medium"
}
```

### D√©tails Techniques

#### **Chargement du Mod√®le**
Au d√©marrage de l'API:
```python
model = joblib.load("fraud_model_xgboost.pkl")
metadata = joblib.load("model_metadata.pkl")
THRESHOLD = metadata.get('threshold', 0.5)
```

#### **Pr√©diction**
1. Conversion de l'input JSON en DataFrame Pandas
2. Passage dans le pipeline (preprocessing + pr√©diction)
3. Extraction de la probabilit√© de la classe 1 (fraude)
4. Comparaison avec le seuil optimis√©
5. Calcul du niveau de risque

#### **Gestion des Erreurs**
- `503 Service Unavailable`: Mod√®le non charg√©
- `500 Internal Server Error`: Erreur lors de la pr√©diction
- **Fix appliqu√©**: Conversion des types numpy en types Python natifs

### D√©marrage
```bash
uvicorn app_fastapi:app --host 0.0.0.0 --port 8000 --reload
```

Acc√®s √† la documentation Swagger: `http://localhost:8000/docs`

---

## Dashboard Interactif (Streamlit)

### Fichier: `dashboard.py`

### Pages du Dashboard

#### **1. Overview (Aper√ßu)**
Statistiques globales du dataset:
- **Total Transactions**: 200 000
- **Cas de Fraude**: ~3 000
- **Taux de Fraude**: ~1.5%
- **Graphique**: Taux de fraude par cat√©gorie de marchand

**Visualisation**:
```
Fraud Rate by Merchant Category
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Travel       (2.8%)   ‚îÇ
‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà Electronics    (2.1%)   ‚îÇ
‚îÇ ‚ñà‚ñà‚ñà‚ñà Fashion          (1.6%)   ‚îÇ
‚îÇ ‚ñà‚ñà‚ñà Grocery           (1.2%)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **2. Real-time Inference**
Formulaire de test de transaction:
- **Champs**: Amount, Merchant Category, Hour, Device, Age, etc.
- **Soumission**: Envoie une requ√™te POST √† l'API
- **R√©sultat**: 
  - Probabilit√© de fraude
  - Niveau de risque (Low/Medium/High)
  - Statut: ‚úÖ Transaction Safe ou üö® FRAUD DETECTED

**Exemple de r√©sultat**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ ‚úÖ Analysis Complete                ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ Fraud Probability: 8.23%           ‚îÇ
‚îÇ Risk Level: Medium                 ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ ‚úÖ Transaction Safe                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### **3. Model Insights**
M√©tadonn√©es du mod√®le:
- **Seuil Optimal**: 0.0174
- **Features Utilis√©es**: 24 features
- (Extension possible: Feature importance, SHAP values)

### Fonctionnalit√©s Techniques

#### **Mise en Cache**
```python
@st.cache_data
def load_data():
    return pd.read_csv(DATA_PATH)

@st.cache_resource
def load_metadata():
    return joblib.load(MODEL_METADATA_PATH)
```

#### **Communication avec l'API**
```python
response = requests.post(API_URL, json=payload)
result = response.json()
```

### D√©marrage
```bash
streamlit run dashboard.py
```

Acc√®s: `http://localhost:8501`

---

## Guide d'Installation

### Pr√©requis
- **Python**: 3.8 ou sup√©rieur
- **Syst√®me d'exploitation**: Windows, macOS, ou Linux
- **RAM**: Minimum 4 GB (8 GB recommand√©)

### √âtapes d'Installation

#### 1. Cloner ou T√©l√©charger le Projet
```bash
cd "c:\Users\FBI\Desktop\Fraud detection"
```

#### 2. Installer les D√©pendances
```bash
pip install -r requirements.txt
```

**Contenu de `requirements.txt`**:
```
pandas
numpy
scikit-learn
matplotlib
seaborn
joblib
xgboost
fastapi
uvicorn
pydantic
streamlit
plotly
```

#### 3. V√©rifier les Fichiers Essentiels
- ‚úÖ `fraud_dataset_realistic_200k.csv` (dataset)
- ‚úÖ `train_advanced.py` (script d'entra√Ænement)
- ‚úÖ `app_fastapi.py` (API)
- ‚úÖ `dashboard.py` (dashboard)
- ‚úÖ `requirements.txt` (d√©pendances)

#### 4. Entra√Æner le Mod√®le (Si N√©cessaire)
```bash
python train_advanced.py
```

**Sortie attendue**:
- `fraud_model_xgboost.pkl` (~860 KB)
- `model_metadata.pkl` (~525 bytes)

**Temps d'ex√©cution**: ~1-2 minutes sur un CPU moderne

---

## Guide d'Utilisation

### Workflow Complet

#### **√âtape 1: Entra√Æner le Mod√®le** (Une fois)
```bash
python train_advanced.py
```

**Ce qui se passe**:
1. Chargement du dataset (200k lignes)
2. Feature engineering et preprocessing
3. Split train/test (80/20)
4. Entra√Ænement XGBoost (200 arbres)
5. √âvaluation sur le test set
6. Optimisation du seuil pour 95% recall
7. Sauvegarde du mod√®le et des m√©tadonn√©es

**Output console**:
```
Loading data from fraud_dataset_realistic_200k.csv...
Preprocessing data...
Categorical columns: ['gender', 'home_country', ...]
Numerical columns: ['transaction_hour', 'age', ...]
Training XGBoost model...

Evaluating model...
Confusion Matrix:
[[38980   306]
 [  145   569]]

Classification Report:
              precision    recall  f1-score
           0       1.00      0.99      0.99
           1       0.65      0.80      0.72
    accuracy                           0.99

ROC-AUC: 0.9415
PR-AUC: 0.7773

Optimal Threshold for 95.0% Recall: 0.0174
Saving model to fraud_model_xgboost.pkl...
Training complete.
```

#### **√âtape 2: D√©marrer l'API Backend**
```bash
uvicorn app_fastapi:app --host 0.0.0.0 --port 8000 --reload
```

**Terminal output**:
```
INFO:     Started server process [12345]
INFO:     Waiting for application startup.
Model loaded. Threshold set to 0.0174
INFO:     Application startup complete.
INFO:     Uvicorn running on http://0.0.0.0:8000
```

**Test manuel de l'API**:
```bash
# Health check
curl http://localhost:8000/health

# Pr√©diction (exemple)
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"transaction_hour": 2, "age": 25, ...}'
```

#### **√âtape 3: Lancer le Dashboard**
Ouvrir un **nouveau terminal**:
```bash
streamlit run dashboard.py
```

**Terminal output**:
```
You can now view your Streamlit app in your browser.
Local URL: http://localhost:8501
Network URL: http://192.168.1.x:8501
```

#### **√âtape 4: Utiliser le Dashboard**
1. Ouvrir `http://localhost:8501` dans le navigateur
2. Naviguer entre les pages via la sidebar
3. Tester des transactions dans "Real-time Inference"
4. Analyser les r√©sultats

---

## R√©sultats et Performance

### M√©triques du Mod√®le (Test Set)

| M√©trique | Valeur | Interpr√©tation |
|----------|--------|----------------|
| **ROC-AUC** | 0.9415 | Excellente discrimination |
| **PR-AUC** | 0.7773 | Tr√®s bonne pr√©cision/rappel |
| **Accuracy** | 0.99 | 99% de transactions bien class√©es |
| **Precision (Fraude)** | 0.65 | 65% des alertes sont vraies |
| **Recall (Fraude)** | 0.80 | 80% des fraudes d√©tect√©es (default) |
| **Recall (Optimis√©)** | 0.95 | 95% des fraudes d√©tect√©es (seuil=0.0174) |

### Matrice de Confusion (Seuil Default = 0.5)

```
                  Pr√©dit: L√©gitime  Pr√©dit: Fraude
R√©el: L√©gitime         38,980            306
R√©el: Fraude              145            569
```

**Interpr√©tation**:
- ‚úÖ **True Negatives (38,980)**: Transactions l√©gitimes correctement identifi√©es
- ‚ùå **False Positives (306)**: Clients bloqu√©s √† tort (0.78% des l√©gitimes)
- ‚ùå **False Negatives (145)**: Fraudes manqu√©es (20% des fraudes)
- ‚úÖ **True Positives (569)**: Fraudes d√©tect√©es (80% des fraudes)

### Performance avec Seuil Optimis√© (0.0174)

√Ä ce seuil, le **Recall passe √† 95%**:
- ‚úÖ **True Positives**: ~678 fraudes d√©tect√©es
- ‚ùå **False Negatives**: ~36 fraudes manqu√©es (5%)
- ‚ö†Ô∏è **False Positives**: Augmentent (trade-off n√©cessaire)

### Courbe Precision-Recall

```
Precision
   ^
1.0‚îÇ     ‚óè
   ‚îÇ      ‚óè
   ‚îÇ       ‚óè
0.8‚îÇ        ‚óè‚óè
   ‚îÇ          ‚óè‚óè
0.6‚îÇ            ‚óè‚óè‚óè
   ‚îÇ               ‚óè‚óè‚óè‚óè
0.4‚îÇ                   ‚óè‚óè‚óè‚óè‚óè
   ‚îÇ                        ‚óè‚óè‚óè‚óè‚óè‚óè‚óè
0.2‚îÇ                              ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
   ‚îÇ                                      ‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè
0.0‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ> Recall
   0.0                                              1.0
```

**Point op√©rationnel**: Recall=0.95, Precision‚âà0.35

### Temps de R√©ponse API

| Op√©ration | Temps Moyen |
|-----------|-------------|
| **Preprocessing** | ~5 ms |
| **Pr√©diction XGBoost** | ~10 ms |
| **Total API** | ~20-30 ms |

**Capacit√©**: ~30-50 requ√™tes/seconde sur CPU standard

### Comparaison avec d'autres Mod√®les

| Mod√®le | ROC-AUC | PR-AUC | Temps Entra√Ænement |
|--------|---------|--------|-------------------|
| **XGBoost** (actuel) | 0.9415 | 0.7773 | ~60 sec |
| Random Forest | ~0.92 | ~0.72 | ~90 sec |
| Logistic Regression | ~0.85 | ~0.55 | ~10 sec |

---

## Am√©liorations Futures

### Court Terme (1-3 mois)
1. **Feature Engineering Avanc√©**
   - Agr√©gations temporelles (rolling windows)
   - Embedding des cat√©gories high-cardinality (merchant_id)
   - Features graph-based (r√©seau de transactions)

2. **Hyperparameter Tuning**
   - Grid Search / Random Search
   - Bayesian Optimization (Optuna)
   - Cross-validation stratifi√©e

3. **Explainabilit√©**
   - SHAP values pour expliquer les pr√©dictions
   - LIME pour les cas individuels
   - Feature importance dynamique

### Moyen Terme (3-6 mois)
4. **Mod√®le Ensemble**
   - XGBoost + LightGBM + CatBoost
   - Stacking / Blending

5. **Monitoring & Alertes**
   - MLflow pour le tracking des exp√©riences
   - Prometheus + Grafana pour le monitoring
   - Alertes automatiques (Slack, Email)

6. **A/B Testing**
   - Test de nouvelles features
   - Comparaison de seuils
   - Feedback loop avec les analystes

### Long Terme (6-12 mois)
7. **Deep Learning**
   - LSTM pour les s√©quences temporelles
   - Autoencoders pour l'anomaly detection
   - Graph Neural Networks pour les patterns de fraude

8. **Production Deployment**
   - Containerisation (Docker)
   - Orchestration (Kubernetes)
   - CI/CD pipeline
   - Load balancing

9. **Real-time Feature Store**
   - Feast ou Tecton
   - Features en temps r√©el (derni√®res 5 min)
   - Synchronisation batch + streaming

10. **Business Intelligence**
    - Dashboard de business metrics
    - Calcul du ROI du mod√®le
    - Analyse des co√ªts (faux positifs vs fraudes manqu√©es)

---

## Structure des Fichiers du Projet

```
Fraud detection/
‚îÇ
‚îú‚îÄ‚îÄ fraud_dataset_realistic_200k.csv     # Dataset principal (200k lignes)
‚îú‚îÄ‚îÄ fraud_dataset_realistic_200k.csv.gz  # Version compress√©e
‚îÇ
‚îú‚îÄ‚îÄ train_advanced.py                    # Script d'entra√Ænement
‚îú‚îÄ‚îÄ app_fastapi.py                       # API Backend
‚îú‚îÄ‚îÄ dashboard.py                         # Dashboard Streamlit
‚îÇ
‚îú‚îÄ‚îÄ fraud_model_xgboost.pkl             # Mod√®le entra√Æn√© (860 KB)
‚îú‚îÄ‚îÄ model_metadata.pkl                   # M√©tadonn√©es (seuil, features)
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt                     # D√©pendances Python
‚îú‚îÄ‚îÄ README.md                            # Cette documentation
‚îÇ
‚îú‚îÄ‚îÄ .git/                                # Git repository
‚îú‚îÄ‚îÄ .gitignore                           # Fichiers ignor√©s par Git
‚îî‚îÄ‚îÄ __pycache__/                         # Cache Python
```

---

## FAQ - Questions Fr√©quentes

### Q: Pourquoi XGBoost et pas un r√©seau de neurones?
**R**: XGBoost est plus adapt√© pour:
- Donn√©es tabulaires (vs images/texte)
- Interpr√©tabilit√© (feature importance)
- Rapidit√© d'entra√Ænement et d'inf√©rence
- Moins de donn√©es n√©cessaires (200k vs millions)

### Q: Comment g√©rer le d√©s√©quilibre des classes?
**R**: Plusieurs techniques appliqu√©es:
- `scale_pos_weight=10` dans XGBoost
- Stratification lors du split
- Optimisation du seuil pour favoriser le Recall
- M√©trique PR-AUC au lieu de ROC-AUC

### Q: Peut-on utiliser ce syst√®me en production?
**R**: Actuellement, c'est un **POC (Proof of Concept)**. Pour la production:
- Ajouter authentification API (OAuth2, API keys)
- Containeriser avec Docker
- Ajouter logging et monitoring robustes
- Mettre en place un pipeline de retraining
- S√©curiser les donn√©es (encryption, RGPD)

### Q: Comment r√©entra√Æner le mod√®le?
**R**: 
```bash
# Avec nouvelles donn√©es
python train_advanced.py

# Le mod√®le sera √©cras√©
# Red√©marrer l'API pour charger le nouveau mod√®le
```

### Q: L'API peut-elle g√©rer plusieurs requ√™tes simultan√©es?
**R**: Oui, FastAPI + Uvicorn supportent l'asyncio. Pour scaler:
```bash
# Plusieurs workers
uvicorn app_fastapi:app --workers 4

# Ou utiliser Gunicorn
gunicorn app_fastapi:app -w 4 -k uvicorn.workers.UvicornWorker
```

### Q: Que signifie "Recall = 95%"?
**R**: Sur 100 transactions frauduleuses:
- Le mod√®le en d√©tecte **95**
- Il en manque **5**

C'est un choix business: pr√©f√©rer d√©tecter plus de fraudes (quitte √† avoir plus de faux positifs).

### Q: Comment ajuster le seuil?
**R**: Modifier `model_metadata.pkl` ou directement dans `app_fastapi.py`:
```python
# Pour plus de pr√©cision (moins de faux positifs)
THRESHOLD = 0.5

# Pour plus de recall (d√©tecter plus de fraudes)
THRESHOLD = 0.01
```

---

## Contact et Support

Pour toute question ou suggestion:
- **GitHub Issues**: git@github.com/Tizeibm/Fraud-detection.git
- **Email**: tizeAhmed750@gmail.com
- **Documentation**: Ce fichier README.md

---

## Licence

Ce projet est √† usage √©ducatif et de d√©monstration.

---

**Derni√®re mise √† jour**: 30 Novembre 2025  
**Version**: 1.0  
**Auteur**: Tize Ibrahim Ahmed
